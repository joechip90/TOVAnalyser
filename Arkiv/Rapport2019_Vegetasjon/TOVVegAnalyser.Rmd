---
title: "Terrestrisk Naturoverv√•king: Vegetasjonsanalyser"
author: "Joseph Chipperfield"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.path = "TOVVegAnalyserFigs/"
)
```

## Import the Libraries

```{r results="hide", warning=FALSE, error=FALSE, message=FALSE}
library(vegan)       # Include the vegetation analysis library
library(ggplot2)     # Import graphics libraries
library(cowplot)     # Import the library to arrange graphics objects
library(rlang)       # R language object library
library(openxlsx)    # Import the files for import/export of Excel data
library(knitr)       # Allow for markdown-formatted tables and figures
library(INLA)        # Use INLA for the regression modelling
library(rjags)       # Library for Bayesian hierarchical modelling
```

## Import the Data

```{r dataImport}
dataLocation <- "C:/Users/joseph.chipperfield/OneDrive - NINA/Work/TOV/CleanedData.rds"
TOVData <- readRDS(dataLocation)

outputLocation <- "C:/Users/joseph.chipperfield/OneDrive - NINA/Work/TOV/AnalyserOutput"
if(dir.exists(outputLocation)) {
  unlink(outputLocation, recursive = TRUE)
}
dir.create(outputLocation)
```

## Set Colours to Use

```{r colourPalette}
# Set the colour palette for the different vegetation layers
TOVData$sjiktInfo <- cbind(TOVData$sjiktInfo, data.frame(
  Colour = rgb(
    c(000, 102, 159, 000, 240, 142, 205, 197),
    c(100, 205, 121, 255, 230, 142, 085, 193),
    c(000, 000, 238, 127, 140, 056, 085, 170), maxColorValue = 255)
))
```

## Initialise Helper Functions

```{r helperFunctions}
# Function to add together columns that are of the same species
compressCommunityMatrix <- function(inputMatrix) {
  # Retrieve the species from the column names
  specNames <- sort(unique(gsub("_[A-Z]$", "", colnames(inputMatrix), perl = TRUE)))
  # Add columns together that belong to the same species
  outputMatrix <- sapply(X = specNames, FUN = function(curSpecies, inputMatrix) {
    speciesMat <- inputMatrix[, curSpecies == gsub("_[A-Z]$", "", colnames(inputMatrix), perl = TRUE), drop = FALSE]
    apply(X = speciesMat, FUN = sum, MARGIN = 1)
  }, inputMatrix = inputMatrix)
  # Make sure the columns and rows are named appropriately
  colnames(outputMatrix) <- specNames
  rownames(outputMatrix) <- rownames(inputMatrix)
  outputMatrix
}

# Produce an analysis of changes in frequency/cover/ordination in different years
yearlyPairwiseWilcoxon <- function(communityMatrix) {
  # Retrieve the site codes
  siteCodes <- sort(unique(gsub("\\d+[A-Z]*\\-\\d+$", "", rownames(communityMatrix), perl = TRUE)))
  outList <- lapply(X = siteCodes, FUN = function(curSite, communityMatrix) {
    # Retrieve just those plots taken at the current site
    communityMatrixSubset <- communityMatrix[grepl(paste("^", curSite, sep = ""), rownames(communityMatrix), perl = TRUE), ]
    # Species list present at site
    speciesList <- colnames(communityMatrixSubset)[apply(X = communityMatrixSubset, FUN = function(curCol) {
      any(curCol > 0)
    }, MARGIN = 2)]
    # Make a list for the analysis of each species
    outList <- lapply(X = speciesList, FUN = function(curSpecies, curSite, communityMatrixSubset) {
      # Find the set of years that the current site has been visited
      yearsVisited <- sort(as.integer(unique(gsub(paste("^", curSite, "\\d+[A-Z]*\\-", sep = ""), "", rownames(communityMatrixSubset), perl = TRUE))))
      # Make a matrix of comparrison years
      yearMatrix <- do.call(rbind, lapply(X = yearsVisited, FUN = function(curYear, yearsVisited) {
        aboveYears <- yearsVisited[curYear < yearsVisited]
        outMat <- matrix(as.integer(c()), ncol = 2, nrow = 0)
        if(length(aboveYears) > 0) {
          outMat <- cbind(rep(curYear, length(aboveYears)), aboveYears)
        }
        colnames(outMat) <- c("fromYear", "toYear")
        outMat
      }, yearsVisited = yearsVisited))
      # Use the matrix of comparrison years to test for differences between species
      cbind(yearMatrix, t(apply(X = yearMatrix, FUN = function(curYears, curSpecies, communityMatrixSubset) {
        # Create two subsets of the community matrix of the 'from' year and the 'to' year
        communityMatrixSubset_fromYear <- communityMatrixSubset[grepl(paste(curYears[1], "$", sep = ""), rownames(communityMatrixSubset), perl = TRUE), ]
        communityMatrixSubset_toYear <- communityMatrixSubset[grepl(paste(curYears[2], "$", sep = ""), rownames(communityMatrixSubset), perl = TRUE), ]
        # Retrieve those plots that are present in both years
        fromPlots <- unique(gsub("\\-\\d+$", "", rownames(communityMatrixSubset_fromYear), perl = TRUE))
        toPlots <- unique(gsub("\\-\\d+$", "", rownames(communityMatrixSubset_toYear), perl = TRUE))
        bothPlots <- sort(c(fromPlots, toPlots)[duplicated(c(fromPlots, toPlots))])
        # Retrieve the values of the community matrix at each year
        values_fromYear <- communityMatrixSubset_fromYear[paste(bothPlots, curYears[1], sep = "-"), curSpecies]
        values_toYear <- communityMatrixSubset_toYear[paste(bothPlots, curYears[2], sep = "-"), curSpecies]
        # Perform the Wilcoxon signed-ranks test
        wilTest <- wilcox.test(values_fromYear, values_toYear, paired = TRUE, exact = FALSE)
        # Produce an output vector with the community data
        setNames(
          c(sum(ifelse(values_fromYear < values_toYear, 1, 0)), sum(ifelse(values_fromYear > values_toYear, 1, 0)), median(values_fromYear), median(values_toYear), mean(values_fromYear), mean(values_toYear), wilTest$statistic, wilTest$p.value),
          c("numIncrease", "numDecrease", "fromMedian", "toMedian", "fromMean", "toMean", "Vstat", "pValue"))
      }, curSpecies = curSpecies, communityMatrixSubset = communityMatrixSubset, MARGIN = 1)))
    }, curSite = curSite, communityMatrixSubset = communityMatrixSubset)
    names(outList) <- speciesList
    outList
  }, communityMatrix = communityMatrix)
  names(outList) <- siteCodes
  outList
}

# Function to calculate compositions of the different functional groups
createFunctionalGroupComposition <- function(communityMatrix) {
  # Get the functional groups from the row names
  sjiktValues <- gsub("^.*_", "", rownames(communityMatrix), perl = TRUE)
  # Retrieve the sjikt composition
  as.data.frame(sapply(X = sort(unique(sjiktValues)), FUN = function(curSjikt, communityMatrix, sjiktValues) {
    # Calculate the total for the current sjikt
    sjiktTotal <- apply(X = communityMatrix[sjiktValues == curSjikt, , drop = FALSE], FUN = sum, MARGIN = 2)
    sjiktTotal / sum(sjiktTotal)
  }, communityMatrix = communityMatrix, sjiktValues = sjiktValues))
}
```

## Ordination Analysis

```{r ordinationAnalysis, results="hide", message=FALSE}
# Function to create trajectory plots when using ordination
createTrajectoryPlot <- function(ordinationFrame, xName, yName, speciesFrame, sjiktInfo) {
  # Retrieve the expressions in the input arguments
  xName <- enquo(xName)
  yName <- enquo(yName)
  # Retrieve the string version of the input arguments
  xNameString <- as_label(xName)
  yNameString <- as_label(yName)
  xNames <- list(qu = xName, str = xNameString)
  yNames <- list(qu = yName, str = yNameString)
  # Retrieve the different site codes in the ordination frame
  siteCodes <- unique(gsub("\\d+[A-Z]*\\-\\d+$", "", rownames(ordinationFrame), perl = TRUE))
  # Create a trajectory plot for each site
  trajPlots <- lapply(X = siteCodes, FUN = function(curSite, ordinationFrame, xNames, yNames) {
    # Subset only the relevant ordination columns at the current site
    ordinationFrameSubset <- as.data.frame(ordinationFrame[grepl(paste("^", curSite, sep = ""), rownames(ordinationFrame), perl = TRUE), c(xNames$str, yNames$str)])
    # Get a list of sampled years at the current site
    sampledYears <- sort(unique(as.integer(gsub("^[A-Z]\\d+[A-Z]*\\-", "", rownames(ordinationFrameSubset), perl = TRUE))))
    # Find the sample that represents the first sample for each plot
    firstSample <- sapply(X = unique(gsub("\\-\\d+$", "", rownames(ordinationFrameSubset), perl = TRUE)), FUN = function(curPlot, plotNames) {
      # Retrieve the years that the plot has been sampled in
      plotYears <- as.integer(gsub(paste("^", curPlot, "\\-", sep = ""), "", plotNames[grepl(paste("^", curPlot, "\\-", sep = ""), plotNames, perl = TRUE)], perl = TRUE))
      paste(curPlot, min(plotYears), sep = "-")
    }, plotNames = rownames(ordinationFrameSubset))
    # Initialise a scatter plot of the ordination values
    outPlot <- ggplot(ordinationFrameSubset[firstSample, ], aes(!!(xNames$qu), !!(yNames$qu))) + theme_classic() +
      xlab(gsub("_.*$", "", xNames$str, perl = TRUE)) + ylab(gsub("_.*$", "", yNames$str, perl = TRUE)) +
      scale_colour_manual(values = colorRampPalette(rgb(c(191, 0), c(239, 178), c(255, 238), maxColorValue = 255))(length(sampledYears) - 1), name = NULL, labels = paste(sampledYears[1:(length(sampledYears) - 1)], sampledYears[2:length(sampledYears)], sep = "-"))
    colnames(ordinationFrameSubset) <- c("ORDX", "ORDY")
    if(length(sampledYears) > 1) {
      # If there is more than one sampled year then plot arrows between each set of years
      # Create a series of data frames for each year transition
      trajOrdinationFrames <- lapply(X = 1:(length(sampledYears) - 1), FUN = function(yearIter, ordinationFrameSubset, sampledYears) {
        # Get the year the plots are going from and to
        fromYear <- sampledYears[yearIter]
        toYear <- sampledYears[yearIter + 1]
        # Find those plots that have samples in both years
        fromPlots <- gsub("\\-\\d+$", "", rownames(ordinationFrameSubset)[grepl(paste(fromYear, "$", sep = ""), rownames(ordinationFrameSubset), perl = TRUE)], perl = TRUE)
        toPlots <- gsub("\\-\\d+$", "", rownames(ordinationFrameSubset)[grepl(paste(toYear, "$", sep = ""), rownames(ordinationFrameSubset), perl = TRUE)], perl = TRUE)
        plotsBoth <- c(fromPlots, toPlots)[duplicated(c(fromPlots, toPlots))]
        # Create a data.frame with the trajectories included
        outTrajFrame <- as.data.frame(matrix(nrow = 0, ncol = 6, dimnames = list(NULL, c("FromYear", "ToYear", "FROM_ORDX", "TO_ORDX", "FROM_ORDY", "TO_ORDY"))))
        if(length(plotsBoth) > 0) {
          outTrajFrame <- data.frame(
            FromYear = factor(rep(fromYear, length(plotsBoth)), levels = sampledYears),
            ToYear = factor(rep(toYear, length(plotsBoth)), levels = sampledYears),
            FROM_ORDX = ordinationFrameSubset[paste(plotsBoth, fromYear, sep = "-"), "ORDX"],
            TO_ORDX = ordinationFrameSubset[paste(plotsBoth, toYear, sep = "-"), "ORDX"],
            FROM_ORDY = ordinationFrameSubset[paste(plotsBoth, fromYear, sep = "-"), "ORDY"],
            TO_ORDY = ordinationFrameSubset[paste(plotsBoth, toYear, sep = "-"), "ORDY"]
          )
          rownames(outTrajFrame) <- plotsBoth
        }
        outTrajFrame
      }, ordinationFrameSubset = ordinationFrameSubset, sampledYears = sampledYears)
      names(trajOrdinationFrames) <- paste(sampledYears[1:(length(sampledYears) - 1)], sampledYears[2:length(sampledYears)], sep = "_")
      # Add trajectory arrows to the ggplot
      outPlot <- outPlot + lapply(X = trajOrdinationFrames, FUN = function(curOrdinationFrame) {
        geom_segment(aes(x = FROM_ORDX, y = FROM_ORDY, xend = TO_ORDX, yend = TO_ORDY, colour = FromYear), data = curOrdinationFrame)
      })
    }
    outPlot + geom_point()
  }, ordinationFrame = ordinationFrame, xNames = xNames, yNames = yNames)
  names(trajPlots) <- siteCodes
  # Create a plot of the species in the Ordination plot
  append(trajPlots, list(
    Sjikt = ggplot(cbind(speciesFrame, data.frame(
      Origin = rep(0.0, nrow(speciesFrame)),
      Sjikt = factor(gsub("^.*\\_", "", rownames(speciesFrame), perl = TRUE), levels = rownames(sjiktInfo))
    )), aes(!!(xNames$qu), !!(yNames$qu))) +
      geom_segment(aes(x = Origin, y = Origin, xend = !!(xNames$qu), yend = !!(yNames$qu), colour = Sjikt), arrow = arrow(type = "closed", length = unit(0.01, "npc"))) +
      theme_classic() + scale_colour_manual(values = as.character(sjiktInfo$Colour), name = NULL, labels = sjiktInfo$DescriptionNorsk) +
      xlab(gsub("_.*$", "", xNames$str, perl = TRUE)) + ylab(gsub("_.*$", "", yNames$str, perl = TRUE))
  ))
}
# Setup community matrices for the frequency values
compressedFreq <- compressCommunityMatrix(t(TOVData$freqMatrix))
# Setup community matrices for the cover values
compressedCover <- compressCommunityMatrix(t(TOVData$coverMatrix))

# Run DCA on each of the different community matrices
compressedFreq_DCA <- decorana(compressedFreq)
compressedCover_DCA <- decorana(compressedCover)

# Run NMDS on each of the different community matrices
compressedFreq_NMDS <- metaMDS(compressedFreq, try = 50, trymax = 10000)
compressedCover_NMDS <- metaMDS(compressedCover, try = 50, trymax = 10000)

# Combine the site scores from the different ordination techniques
compressedFreq_Ordination <- list(
  plots = as.data.frame(cbind(scores(compressedFreq_DCA), scores(compressedFreq_NMDS))),
  species = as.data.frame(
    cbind(scores(compressedFreq_DCA, display = "species"), scores(compressedFreq_NMDS, display = "species"))
      )[gsub("_[A-Z]+$", "", rownames(TOVData$speciesInfo), perl = TRUE), ]
)
names(compressedFreq_Ordination$plots) <- paste(names(compressedFreq_Ordination$plots), "Frekvens", sep = "_")
names(compressedFreq_Ordination$species) <- paste(names(compressedFreq_Ordination$species), "Frekvens", sep = "_")
rownames(compressedFreq_Ordination$species) <- rownames(TOVData$speciesInfo)
compressedCover_Ordination <- list(
  plots = as.data.frame(cbind(scores(compressedCover_DCA), scores(compressedCover_NMDS))),
  species = as.data.frame(
    cbind(scores(compressedCover_DCA, display = "species"), scores(compressedCover_NMDS, display = "species"))
      )[gsub("_[A-Z]+$", "", rownames(TOVData$speciesInfo), perl = TRUE), ]
)
names(compressedCover_Ordination$plots) <- paste(names(compressedCover_Ordination$plots), "Dekning", sep = "_")
names(compressedCover_Ordination$species) <- paste(names(compressedCover_Ordination$species), "Dekning", sep = "_")
rownames(compressedCover_Ordination$species) <- rownames(TOVData$speciesInfo)
# Add the frequency and cover information to the plot information
TOVData$plotInfo <- cbind(TOVData$plotInfo, compressedFreq_Ordination$plots, compressedCover_Ordination$plots)
TOVData$speciesInfo <- cbind(TOVData$speciesInfo, compressedFreq_Ordination$species, compressedCover_Ordination$species)

# Function to write the results of the Wilcoxon signed ranks test to an ordination output file
writeOrdinationYeralyPairwise <- function(yearlyPairwiseList, outWorkbook, sheetName, siteInfo) {
  # Create a flattened version of the ordination scores
  flattenedOrdinationFrame <- do.call(rbind, lapply(X = names(yearlyPairwiseList), FUN = function(curSiteCode, yearlyPairwiseList, siteInfo) {
    # Retrieve the current site name
    curSiteName <- siteInfo[curSiteCode, "SiteName"]
    # Retrieve the current ordination list
    curOrdinationList <- yearlyPairwiseList[[curSiteCode]]
    outMat <- t(sapply(X = curOrdinationList, FUN = function(curOrdinationScores) {
      # Flatten out the ordination scores
      setNames(
        as.vector(t(as.matrix(curOrdinationScores[, 3:ncol(curOrdinationScores)]))),
        sapply(X = paste(curOrdinationScores[, 1], curOrdinationScores[, 2], sep = "_"), FUN = paste, colnames(curOrdinationScores)[3:ncol(curOrdinationScores)], sep = "_")
      )
    }))
    rownames(outMat) <- paste(curSiteCode, names(curOrdinationList), sep = "_")
    as.data.frame(outMat)
  }, yearlyPairwiseList = yearlyPairwiseList, siteInfo = siteInfo))
  # Get the vector of year comparrisons
  uniqueYearComps <- unique(sapply(X = strsplit(colnames(flattenedOrdinationFrame), "_", fixed = TRUE), FUN = function(curSplit) {
    paste(curSplit[1], curSplit[2], sep = "-")
  }))
  # Get the vector of ordination axes
  uniqueOrdAxes <- unique(sapply(X = strsplit(rownames(flattenedOrdinationFrame), "_", fixed = TRUE), FUN = function(curSplit) {
    curSplit[2]
  }))
  # Make text for the top header
  topHeadText <- c("Site", "Ordination Axis", unlist(lapply(X = uniqueYearComps, FUN = function(curComp) {
    c(paste(curComp, "Comparison", sep = " "), rep("", 5))
  })))
  dim(topHeadText) <- c(1, length(topHeadText))
  # Make text for the lower header
  lowerHeadText <- c("", "", unlist(lapply(X = uniqueYearComps, FUN = function(curComp) {
    # Get the split years
    splitCom <- strsplit(curComp, "-", fixed = TRUE)[[1]]
    c("N Increasing", "N Decreasing", paste("Median (", splitCom, ")", sep = ""), "Wilcoxon's V", "P Value")
  })))
  dim(lowerHeadText) <- c(1, length(lowerHeadText))
  # Make text for the site column
  siteColumnText <- unlist(lapply(X = as.character(siteInfo[, "SiteName"]), FUN = function(curSiteName, numAxes) {
    initOut <- rep("", numAxes)
    initOut[1] <- curSiteName
    initOut
  }, numAxes = length(uniqueOrdAxes)))
  dim(siteColumnText) <- c(length(siteColumnText), 1)
  # Get the column names of the output that we want
  outputColNames <- unlist(lapply(X = uniqueYearComps, FUN = function(curComp) {
    yearFormat <- gsub("-", "_", curComp, fixed = TRUE)
    paste(yearFormat, c("numIncrease", "numDecrease", "fromMedian", "toMedian", "Vstat", "pValue"), sep = "_")
  }))
  # Write the elements of the worksheet
  writeData(outWorkbook, sheetName, topHeadText, rowNames = FALSE, colNames = FALSE, startCol = 1, startRow = 1)
  writeData(outWorkbook, sheetName, lowerHeadText, rowNames = FALSE, colNames = FALSE, startCol = 1, startRow = 2)
  writeData(outWorkbook, sheetName, siteColumnText, rowNames = FALSE, colNames = FALSE, startCol = 1, startRow = 3)
  writeData(outWorkbook, sheetName, cbind(data.frame(
      OrdinationAxis = rep(uniqueOrdAxes, nrow(siteInfo))
    ),
    flattenedOrdinationFrame[, outputColNames]), rowNames = FALSE, colNames = FALSE, startCol = 2, startRow = 3)
  # Add styles for the column headers
  topHeadStyle <- createStyle(textDecoration = "bold")
  lowerHeadStyle <- createStyle(border = "bottom", borderStyle = "medium")
  addStyle(outWorkbook, sheetName, style = topHeadStyle, rows = 1, cols = 1:length(topHeadText))
  addStyle(outWorkbook, sheetName, style = lowerHeadStyle, rows = 2, cols = 1:length(topHeadText))
  # Merge the cells of the top header
  lapply(X = 1:length(uniqueYearComps), FUN = function(curNum, outWorkbook, sheetName, repRange) {
    mergeCells(outWorkbook, sheetName, cols = ((curNum - 1) * repRange):(curNum * repRange - 1) + 3, rows = 1)
  }, outWorkbook = outWorkbook, sheetName = sheetName, repRange = 6)
  # Merge the cells of the first row
  lapply(X = 1:nrow(siteInfo), FUN = function(curNum, outWorkbook, sheetName, repRange) {
    mergeCells(outWorkbook, sheetName, cols = 1, rows = ((curNum - 1) * repRange):(curNum * repRange - 1) + 3)
  }, outWorkbook = outWorkbook, sheetName = sheetName, repRange = length(uniqueOrdAxes))
  outWorkbook
}

# Calculate yearly pairwise estimates of changes in the ordination axes
ordinationFreq_yearlyPairwise <- yearlyPairwiseWilcoxon(compressedFreq_Ordination$plots)
ordinationCover_yearlyPairwise <- yearlyPairwiseWilcoxon(compressedCover_Ordination$plots)

# Save the ordination scores in Excel files
ordinationBook <- createWorkbook()
addWorksheet(ordinationBook, "Jordstykker_Frekvens")
addWorksheet(ordinationBook, "Jordstykker_Dekning")
addWorksheet(ordinationBook, "Arter_Frekvens")
addWorksheet(ordinationBook, "Arter_Dekning")
addWorksheet(ordinationBook, "√Örlig_Frekvens")
addWorksheet(ordinationBook, "√Örlig_Dekning")
ordHeaderStyle <- createStyle(border = "bottom", borderStyle = "medium", textDecoration = "bold")
writeDataTable(ordinationBook, "Jordstykker_Frekvens", compressedFreq_Ordination$plots, headerStyle = ordHeaderStyle, rowNames = TRUE, firstColumn = TRUE)
writeDataTable(ordinationBook, "Jordstykker_Dekning", compressedCover_Ordination$plots, headerStyle = ordHeaderStyle, rowNames = TRUE, firstColumn = TRUE)
writeDataTable(ordinationBook, "Arter_Frekvens", compressedFreq_Ordination$species, headerStyle = ordHeaderStyle, rowNames = TRUE, firstColumn = TRUE)
writeDataTable(ordinationBook, "Arter_Dekning", compressedCover_Ordination$species, headerStyle = ordHeaderStyle, rowNames = TRUE, firstColumn = TRUE)
writeOrdinationYeralyPairwise(ordinationFreq_yearlyPairwise, ordinationBook, "√Örlig_Frekvens", TOVData$siteInfo)
writeOrdinationYeralyPairwise(ordinationCover_yearlyPairwise, ordinationBook, "√Örlig_Dekning", TOVData$siteInfo)
saveWorkbook(ordinationBook, paste(outputLocation, "OrdinationScores.xlsx", sep = "/"), overwrite = TRUE)

# Create a series of trajectory plots for the DCA scores
freqDCAOrdinationPlotList <- createTrajectoryPlot(compressedFreq_Ordination$plots, DCA1_Frekvens, DCA2_Frekvens, compressedFreq_Ordination$species, TOVData$sjiktInfo)
coverDCAOrdinationPlotList <- createTrajectoryPlot(compressedCover_Ordination$plots, DCA1_Dekning, DCA2_Dekning, compressedCover_Ordination$species, TOVData$sjiktInfo)
# Create a series of trajectory plots for the NMDS scores
freqNMDSOrdinationPlotList <- createTrajectoryPlot(compressedFreq_Ordination$plots, NMDS1_Frekvens, NMDS2_Frekvens, compressedFreq_Ordination$species, TOVData$sjiktInfo)
coverNMDSOrdinationPlotList <- createTrajectoryPlot(compressedCover_Ordination$plots, NMDS1_Dekning, NMDS2_Dekning, compressedCover_Ordination$species, TOVData$sjiktInfo)
```

```{r ordinationPlotSave, echo=FALSE, results="hide", warning=FALSE, error=FALSE, message=FALSE}
# Function to save the ordination plots
saveOrdinationPlots <- function(curPlotList, outputLocation, siteInfo, suffix) {
  lapply(X = names(curPlotList), FUN = function(curSiteCode, curPlotList, outputLocation, siteInfo, suffix) {
    # Retrieve the full site name (unless it is the species entry)
    fullSiteName <- "Species"
    if(curSiteCode %in% rownames(siteInfo)) {
      fullSiteName <- siteInfo[curSiteCode, "SiteName"]
    }
    # Save the ordination plot as an SVG object
    ggsave(file = paste(outputLocation, "/", fullSiteName, suffix, ".svg", sep = ""), curPlotList[[curSiteCode]], width = 10, height = 8)
  }, curPlotList = curPlotList, outputLocation = outputLocation, siteInfo = siteInfo, suffix = suffix)
}
# Save each of the ordination plots
saveOrdinationPlots(freqDCAOrdinationPlotList, outputLocation, TOVData$siteInfo, "_FrekvensDCA")
saveOrdinationPlots(coverDCAOrdinationPlotList, outputLocation, TOVData$siteInfo, "_DekningDCA")
saveOrdinationPlots(freqNMDSOrdinationPlotList, outputLocation, TOVData$siteInfo, "_FrekvensNMDS")
saveOrdinationPlots(coverNMDSOrdinationPlotList, outputLocation, TOVData$siteInfo, "_DekningNMDS")
```

## Compositional Analysis

```{r compositionalAnalysis}
# Function to produce a compositional model
# makeCompositionalModel <- function(sjiktFrame, sjiktInfo) {
#   MCMCParams <- list(
#     numChains = 4,
#     numAdapt = 5000,
#     numSamples = 10000,
#     numThin = 1
#   )
#   # Retrieve information about each plot
#   retPlotInfo <- data.frame(
#     siteCode = factor(gsub("\\d+[A-Z]*\\-\\d+$", "", rownames(sjiktFrame), perl = TRUE)),
#     plotID = factor(gsub("^[A-Z]", "", gsub("\\-\\d+$", "", rownames(sjiktFrame), perl = TRUE), perl = TRUE)),
#     year = as.integer(gsub("^[A-Z]\\d+[A-Z]*\\-", "", rownames(sjiktFrame), perl = TRUE))
#   )
#   # Retrieve a temporary file name to hold the model specification
#   tempModelFile <- tempfile()
#   cat("model {
#     ### LIKELIHOOD SPECIFICATION ####
#     for(dataIter in 1:numData) {
#       # Use a linear-model specification for each element of the composition
#       for(sjiktIter in 1:numSjikt) {
#         log(linPred[dataIter, sjiktIter]) <- interceptCoeff[sjiktIter] +
#           sjiktSiteCoeff[siteIndex[dataIter], sjiktIter] + sjiktPlotCoeff[plotIndex[dataIter], sjiktIter] +
#           yearCoeff[sjiktIter] * year[dataIter] + yearSiteCoeff[siteIndex[dataIter], sjiktIter] * year[dataIter]
#       }
#       # Specify a Dirichlet error distribution
#       sjiktComposition[dataIter, 1:numSjikt] ~ ddirch(linPred[dataIter, 1:numSjikt])
#     }
#     ### PRIOR SPECIFICATION ###
#     # Initialise zero values for all fixed effects in the first sjikt
#     interceptCoeff[1] <- 0.0
#     yearCoeff[1] <- 0.0
#     for(priorSiteIterF in 1:numSites) {
#       yearSiteCoeff[priorSiteIterF, 1] <- 0.0
#       sjiktSiteCoeff[priorSiteIterF, 1] <- 0.0
#     }
#     # Set priors for random effects in the first sjikt
#     plotPrec[1] ~ dgamma(0.001, 0.001)
#     for(priorPlotIterF in 1:numPlots) {
#       sjiktPlotCoeff[priorPlotIterF, 1] ~ dnorm(0.0, plotPrec[1])
#     }
#     # Set priors for the other sjikt parameters
#     for(priorSjiktIter in 2:numSjikt) {
#       # Set priors for the fixed effects (setting the first element to zero)
#       interceptCoeff[priorSjiktIter] ~ dnorm(0.0, 0.001)
#       yearCoeff[priorSjiktIter] ~ dnorm(0.0, 0.001)
#       yearSiteCoeff[1, priorSjiktIter] <- 0.0
#       sjiktSiteCoeff[1, priorSjiktIter] <- 0.0
#       for(priorSiteIter in 2:numSites) {
#         yearSiteCoeff[priorSiteIter, priorSjiktIter] ~ dnorm(0.0, 0.001)
#         sjiktSiteCoeff[priorSiteIter, priorSjiktIter] ~ dnorm(0.0, 0.001)
#       }
#       # Set priors for the random effects
#       plotPrec[priorSjiktIter] ~ dgamma(0.001, 0.001)
#       for(priorPlotIter in 1:numPlots) {
#         sjiktPlotCoeff[priorPlotIter, priorSjiktIter] ~ dnorm(0.0, plotPrec[priorSjiktIter])
#       }
#     }
#     ### DERIVED VARIABLES ###
#     for(derivedSjiktIter in 1:numSjikt) {
#       # Derive a total year effect for each sjikt
#       for(derivedSiteIter in 1:numSites) {
#         yearEffect[derivedSiteIter, derivedSjiktIter] <- yearCoeff[derivedSjiktIter] + yearSiteCoeff[derivedSiteIter, derivedSjiktIter]
#       }
#     }
#   }", file = tempModelFile)
#   # Set the JAGS data list
#   jagsData <- list(
#     # Set the number of sjikts, data points, sites and plots
#     numSjikt = ncol(sjiktFrame),
#     numData = nrow(sjiktFrame),
#     numSites = length(levels(retPlotInfo$siteCode)),
#     numPlots = length(levels(retPlotInfo$plotID)),
#     # Set the covariate information
#     siteIndex = as.integer(retPlotInfo$siteCode),
#     plotIndex = as.integer(retPlotInfo$plotID),
#     year = retPlotInfo$year,
#     # Set the community composition
#     sjiktComposition = t(apply(X = as.matrix(sjiktFrame), FUN = function(curRow) {
#       curRow / sum(curRow)
#     }, MARGIN = 1))
#   )
#   # Initialise the JAGS model
#   sjiktModel <- jags.model(tempModelFile, jagsData, n.chains = MCMCParams$numChains, n.adapt = MCMCParams$numAdapt)
#   # Save the model outputs
#   outSamples <- coda.samples(sjiktModel, c("interceptCoeff", "sjiktSiteCoeff", "yearEffect"), n.iter = MCMCParams$numSamples, thin = MCMCParams$numThin)
#   list(compositionModel = sjiktModel, mcmcSamples = outSamples)
# }
# freqCompositionModel <- makeCompositionalModel(createFunctionalGroupComposition(TOVData$freqMatrix))
```

## Yearly-Pairwise Analysis for Each Species

```{r yearlyRichness, results="asis"}
outWorkbook <- createWorkbook()
richnessList <- lapply(X = rownames(TOVData$siteInfo), FUN = function(curSiteCode, communityMatrix, siteInfo, sjiktInfo, outWorkbook) {
  # Current site name
  curSiteName <- as.character(siteInfo[curSiteCode, "SiteName"])
  # Initialise a worksheet for the current site
  addWorksheet(outWorkbook, curSiteName)
  # Subset the matrix with the current site code
  curCommunityMatrix <- communityMatrix[, gsub("\\d+[A-Z]*\\-\\d+$", "", colnames(communityMatrix), perl = TRUE) == curSiteCode]
  # Create a richness matrix
  richnessMatrix <- as.data.frame(sapply(X = unique(gsub(paste("^", curSiteCode, "\\d+[A-Z]*\\-", sep = ""), "", colnames(curCommunityMatrix), perl = TRUE)), FUN = function(curYear, curCommunityMatrix, sjiktInfo) {
    # Filter out the columns that represent samples from the current year
    curYearCommunity <- curCommunityMatrix[, grepl(paste(curYear, "$", sep = ""), colnames(curCommunityMatrix), perl = TRUE)]
    # Count the species richness for each sjikt
    setNames(sapply(X = sjiktInfo$SjiktCode, FUN = function(curSjikt, curYearCommunity) {
      # Assess whether the species row belong to the current sjikt
      isSjikt <- grepl(paste(curSjikt, "$", sep = ""), rownames(curYearCommunity), perl = TRUE)
      outVal <- 0
      if(any(isSjikt)) {
        outVal <- sum(ifelse(apply(X = curYearCommunity[isSjikt, , drop = FALSE], FUN = function(curRow) {
          any(curRow > 0)
        }, MARGIN = 1), 1, 0))
      }
      outVal
    }, curYearCommunity), sjiktInfo$SjiktCode)
  }, curCommunityMatrix = curCommunityMatrix, sjiktInfo = sjiktInfo))
  # Save the table to the workbook
  formattedTable <- cbind(data.frame(Sjikt = rownames(sjiktInfo)), richnessMatrix)
  writeDataTable(outWorkbook, curSiteName, formattedTable, colNames = TRUE, rowNames = FALSE)
  # Display a table
  outTable <- cbind(data.frame(Sjikt = sjiktInfo[, "DescriptionNorsk"]), as.data.frame(richnessMatrix))
  cat("**Species richness at ", curSiteName, "**\n", sep = "")
  print(kable(outTable, format = "markdown", row.names = FALSE, caption = paste("Species richness at", curSiteName, sep = " ")))
  richnessMatrix
}, communityMatrix = TOVData$freqMatrix, siteInfo = TOVData$siteInfo, sjiktInfo = TOVData$sjiktInfo, outWorkbook = outWorkbook)
names(richnessList) <- rownames(TOVData$siteInfo)
# Save the created workbook
saveWorkbook(outWorkbook, paste(outputLocation, "/SpeciesRichness.xlsx", sep = ""), TRUE)
```

```{r yearlyPairwise, results="hide"}
# Run the yearly pairwise analysis for both the cover and the frequency
compressedFreq_yearlyPairwise <- yearlyPairwiseWilcoxon(compressedFreq)
compressedCover_yearlyPairwise <- yearlyPairwiseWilcoxon(compressedCover)
# Create a set of Excel files containing the pairwise analyses
lapply(X = names(compressedFreq_yearlyPairwise), FUN = function(curSiteCode, freqPairwise, coverPairwise, siteInfo, outputLocation, speciesInfo) {
  # Retrieve the full size name
  fullSiteName <- siteInfo[curSiteCode, "SiteName"]
  # Create a workbook
  siteWorkbook <- createWorkbook()
  # Create sheets for the cover and frequency
  freqSheet <- addWorksheet(siteWorkbook, sheetName = "Frekvens")
  coverSheet <- addWorksheet(siteWorkbook, sheetName = "Dekning")
  # Function to rearrange a species list to a pairwise year data frame
  rearrangePairwiseYears <- function(curSpeciesList) {
    outFrame <- t(sapply(X = curSpeciesList, FUN = function(curYearAnalysis) {
      # Flatten out the input matrix
      setNames(as.double(t(curYearAnalysis[, c("fromMedian", "toMedian", "fromMean", "toMean", "Vstat", "pValue")])), unlist(lapply(X = paste(curYearAnalysis[, 1], curYearAnalysis[, 2], sep = "-"), FUN = function(curYearText, addColumnHeads) {
        paste(curYearText, addColumnHeads, sep = "_")
      }, addColumnHeads = c("fromMedian", "toMedian", "fromMean", "toMean", "Vstat", "pValue"))))
    }))
    rownames(outFrame) <- names(curSpeciesList)
    outFrame
  }
  # Function to write the pairwise yearly analysis to a worksheet
  writePairwiseYearsSheet <- function(freqTable, siteWorkbook, sheetName, speciesInfo) {
    # Retrieve the vector of comparrison years
    freqYears <- unique(gsub("_.*$", "", colnames(freqTable), perl = TRUE))
    # Initialise a comparrison years vector
    freqYearHeaders <- rep("", 6 * length(freqYears))
    freqYearHeaders[0:(length(freqYearHeaders) - 1) %% 6 == 0] <- paste(freqYears, "Comparison", sep = " ")
    dim(freqYearHeaders) <- c(1, length(freqYearHeaders))
    freqYearHeaders <- cbind("Species", freqYearHeaders)
    # Initialise the species row names
    freqSpecies <- speciesInfo[rownames(freqTable)]
    dim(freqSpecies) <- c(length(freqSpecies), 1)
    # Initialise a column headings vector
    columnHeadings <- c("Median", "Median", "Mean", "Mean", "Wilcoxon's V", "P Value")
    repColumnHeadings <- unlist(lapply(X = freqYears, FUN = function(curYearComp, columnHeadings) {
      # Retrieve the years being compared
      inYears <- c(paste(" (", strsplit(curYearComp, "-", fixed = TRUE)[[1]], ")", sep = ""), "")
      # Add the year information to the relevant columns
      paste(columnHeadings, inYears[c(1, 2, 1, 2, 3, 3)], sep = "")
    }, columnHeadings = columnHeadings))
    dim(repColumnHeadings) <- c(1, length(repColumnHeadings))
    # Write the elements of the worksheet
    writeData(siteWorkbook, sheetName, freqYearHeaders, rowNames = FALSE, colNames = FALSE, startCol = 1, startRow = 1)
    writeData(siteWorkbook, sheetName, repColumnHeadings, rowNames = FALSE, colNames = FALSE, startCol = 2, startRow = 2)
    writeData(siteWorkbook, sheetName, freqSpecies, rowNames = FALSE, colNames = FALSE, startCol = 1, startRow = 3)
    writeData(siteWorkbook, sheetName, freqTable, rowNames = FALSE, colNames = FALSE, startCol = 2, startRow = 3)
    # Add conditional formatting to the Wilcox p-values when significant
    sigIncStyle <- createStyle(bgFill = rgb(193, 255, 193, maxColorValue = 255))
    sigDecStyle <- createStyle(bgFill = rgb(255, 182, 193, maxColorValue = 255))
    lapply(X = 1 + length(columnHeadings) + 0:(length(freqYears)) * length(columnHeadings), FUN = function(curCol, numSpecies, siteWorkbook, sheetName, sigIncStyle, sigDecStyle) {
      conditionalFormatting(siteWorkbook, sheetName, cols = curCol, rows = 1:numSpecies + 2, style = sigIncStyle, rule = paste("AND(", int2col(curCol), "3<=0.05,", int2col(curCol - 3), "3<", int2col(curCol - 2), "3)", sep = ""))
      conditionalFormatting(siteWorkbook, sheetName, cols = curCol, rows = 1:numSpecies + 2, style = sigDecStyle, rule = paste("AND(", int2col(curCol), "3<=0.05,", int2col(curCol - 3), "3>", int2col(curCol - 2), "3)", sep = ""))
    }, numSpecies = length(freqSpecies), siteWorkbook = siteWorkbook, sheetName = sheetName, sigIncStyle = sigIncStyle, sigDecStyle = sigDecStyle)
    # Merge the comparison cells
    lapply(X = 1:length(freqYears), FUN = function(curIter, colLength, siteWorkbook, sheetName) {
      mergeCells(siteWorkbook, sheetName, cols = ((curIter - 1) * colLength):(curIter * colLength - 1) + 2, rows = 1)
    }, colLength = length(columnHeadings), siteWorkbook, sheetName)
    # Style the column headers
    topHeadStyle <- createStyle(textDecoration = "bold")
    lowerHeadStyle <- createStyle(border = "bottom", borderStyle = "medium")
    addStyle(siteWorkbook, sheetName, style = topHeadStyle, rows = 1, cols = 1:ncol(freqYearHeaders))
    addStyle(siteWorkbook, sheetName, style = lowerHeadStyle, rows = 2, cols = 1:ncol(freqYearHeaders))
    # Style the species names
    speciesStyle <- createStyle(textDecoration = "italic")
    addStyle(siteWorkbook, sheetName, style = speciesStyle, rows = 1:nrow(freqSpecies) + 2, cols = 1)
    siteWorkbook
  }
  # Flatten out the cover and frequency analyses
  freqTable <- rearrangePairwiseYears(freqPairwise[[curSiteCode]])
  writePairwiseYearsSheet(freqTable, siteWorkbook, "Frekvens", speciesInfo)
  coverTable <- rearrangePairwiseYears(coverPairwise[[curSiteCode]])
  writePairwiseYearsSheet(coverTable, siteWorkbook, "Dekning", speciesInfo)
  # Save the workbook
  saveWorkbook(siteWorkbook, paste(outputLocation, "/", fullSiteName, "_yearlyPairwise.xlsx", sep = ""), overwrite = TRUE)
}, freqPairwise = compressedFreq_yearlyPairwise, coverPairwise = compressedCover_yearlyPairwise, siteInfo = TOVData$siteInfo, outputLocation = outputLocation,
  # Arrange the species information in an easy lookup vector
  speciesInfo = setNames(sapply(X = colnames(compressedFreq), FUN = function(curSpecCode, speciesInfo) {
    unique(speciesInfo[gsub("_[A-Z]$", "", rownames(speciesInfo), perl = TRUE) == curSpecCode, "SpeciesBinomial"])[1]
  }, speciesInfo = TOVData$speciesInfo), colnames(compressedFreq)))
```
## Ellenberg Indicator Value Analysis

```{r ellenbergAnalysis}
# Ellenberg column names to use in the analysis
ellenbergColNames <- c("L", "F", "R", "N")
ellenbergDescriptionNorsk <- setNames(c("Lys", "Fuktighet", "Reaksjon (baserikhet)", "Nitrogen"), ellenbergColNames)
attr(ellenbergDescriptionNorsk, "dispColours") <- rgb(c(255, 176, 255, 180), c(250, 226, 192, 238), c(205, 255, 203, 180), maxColorValue = 255)
# Set the maximum and minimum values of the Ellenberg indicator values
attr(ellenbergDescriptionNorsk, "range") <- matrix(c(
  1, 1, 1, 1,
  9, 12, 9, 9
), nrow = 2, byrow = TRUE, dimnames = list(c("min", "max"), ellenbergColNames))
# Open a workbook for the Ellenberg analysis
ellenbergWorkbook <- createWorkbook()
# Create an Excel sheet of the species Ellenberg values
addWorksheet(ellenbergWorkbook, "Species")
writeDataTable(ellenbergWorkbook, "Species", TOVData$speciesInfo, rowNames = TRUE)
# Create frequency and cover weighted mean of each of the Ellenberg values for each plot
addWorksheet(ellenbergWorkbook, "PlotsFrek")
addWorksheet(ellenbergWorkbook, "PlotsDekning")
# Calculate the Ellenberg values for a plot
calcPlotEllenberg <- function(curPlotCommunity, ellenbergSpeciesMatrix) {
  # Calculate a matrix of plot Ellenberg values
  plotEllenbergMat <- apply(X = ellenbergSpeciesMatrix, FUN = function(curEllenbergVals, curPlotCommunity) {
    totalVal <- sum(curPlotCommunity, na.rm = TRUE)
    ellenVal <- sum(curEllenbergVals * curPlotCommunity, na.rm = TRUE)
    hasDataVal <- sum(ifelse(is.na(curEllenbergVals), 0, 1) * curPlotCommunity, na.rm = TRUE)
    setNames(c(ellenVal, hasDataVal) / totalVal, c("Val", "PropData"))
  }, curPlotCommunity = curPlotCommunity, MARGIN = 2)
  # Rearrange the outputs
  setNames(c(plotEllenbergMat[1, ], plotEllenbergMat[2, ]), c(colnames(ellenbergSpeciesMatrix), paste(colnames(ellenbergSpeciesMatrix), "PropData", sep = "")))
}
# Calculate the Ellenberg value for each plot (using both frequency and cover)
freqEllenbergValues <- t(apply(X = TOVData$freqMatrix, FUN = calcPlotEllenberg, ellenbergSpeciesMatrix = as.matrix(TOVData$speciesInfo[, ellenbergColNames]), MARGIN = 2))
coverEllenbergValues <- t(apply(X = TOVData$coverMatrix, FUN = calcPlotEllenberg, ellenbergSpeciesMatrix = as.matrix(TOVData$speciesInfo[, ellenbergColNames]), MARGIN = 2))
writeDataTable(ellenbergWorkbook, "PlotsFrek", as.data.frame(freqEllenbergValues), rowNames = TRUE)
writeDataTable(ellenbergWorkbook, "PlotsDekning", as.data.frame(coverEllenbergValues), rowNames = TRUE)
# Include all the Ellenberg information available in the input data
addWorksheet(ellenbergWorkbook, "AllValues")
writeDataTable(ellenbergWorkbook, "AllValues", TOVData$ellenbergData)
saveWorkbook(ellenbergWorkbook, paste(outputLocation, "/EllenbergValues.xlsx", sep = ""), overwrite = TRUE)

# Function to fit a linear regression model to the Ellenberg data
fitEllenbergModel <- function(curEllenbergVal, ellenbergFrame, ellenbergInfo) {
   # Make a data frame to conduct the Ellenberg model analysis on
   modelFrame <- data.frame(
     # Retrieve the plot information from the ID code
     site = factor(gsub("\\d+[A-Z]*\\-\\d+$", "", rownames(ellenbergFrame), perl = TRUE)),
     plot = factor(gsub("\\-\\d+$", "", rownames(ellenbergFrame), perl = TRUE)),
     year = as.double(gsub("^[A-Z]\\d+[A-Z]*\\-", "", rownames(ellenbergFrame), perl = TRUE)),
     # Get the current Ellenberg value (correcting for the minimum and maximum values of the Ellenberg indicator)
     ellenbergValue = (ellenbergFrame[, curEllenbergVal] - attr(ellenbergInfo, "range")["min", curEllenbergVal]) / diff(attr(ellenbergDescriptionNorsk, "range")[, curEllenbergVal])
   )
   rownames(modelFrame) <- rownames(ellenbergFrame)
   # Create a series of linear combinations to monitor the overall effect of Year at each site
   monitorLinCombs <- do.call(c, lapply(X = levels(modelFrame$site), FUN = function(curSite, modelNames) {
     interactionCoeffName <- paste("site", curSite, ":year", sep = "")
     monitorVec <- setNames(1, "year")
     if(interactionCoeffName %in% modelNames) {
       monitorVec <- c(monitorVec, setNames(1, interactionCoeffName))
     }
     outVal <- do.call(inla.make.lincomb, as.list(monitorVec))
     names(outVal) <- curSite
     outVal
   }, modelNames = colnames(model.matrix(ellenbergValue ~ site * year, data = modelFrame))))
   # Run INLA on the Ellenberg data
   inla(ellenbergValue ~ site * year + f(plot, model = "iid"), data = modelFrame, family = "beta", control.predictor = list(compute = TRUE), lincomb = monitorLinCombs)
}
# Fit the INLA regression model for the frequency and cover data
freqEllenbergModels <- lapply(X = names(ellenbergDescriptionNorsk), FUN = fitEllenbergModel, ellenbergFrame = freqEllenbergValues, ellenbergInfo = ellenbergDescriptionNorsk)
names(freqEllenbergModels) <- names(ellenbergDescriptionNorsk)
coverEllenbergModels <- lapply(X = names(ellenbergDescriptionNorsk), FUN = fitEllenbergModel, ellenbergFrame = coverEllenbergValues, ellenbergInfo = ellenbergDescriptionNorsk)
names(coverEllenbergModels) <- names(ellenbergDescriptionNorsk)
```

```{r ellenbergAnalysisPlots, warning=FALSE}
# Function to make plots of the Ellenberg values calculated at each plot
makeEllenbergPlotList <- function(curSiteInfo, ellenbergValues, ellenbergDescription, outputLocation, fileSuffix, modelList) {
  # Retrieve the current site name and site code
  curSiteName <- curSiteInfo[1]
  curSiteCode <- curSiteInfo[2]
  # Retrieve information about each plot
  retPlotInfo <- data.frame(
    siteCode = gsub("\\d+[A-Z]*\\-\\d+$", "", rownames(ellenbergValues), perl = TRUE),
    plotID = gsub("^[A-Z]", "", gsub("\\-\\d+$", "", rownames(ellenbergValues), perl = TRUE), perl = TRUE),
    year = as.integer(gsub("^[A-Z]\\d+[A-Z]*\\-", "", rownames(ellenbergValues), perl = TRUE))
  )
  rownames(retPlotInfo) <- rownames(ellenbergValues)
  # Reorder the Ellenberg values
  rowsToUse <- as.character(retPlotInfo$siteCode) == curSiteCode
  reorderedEllenberg <- do.call(rbind, lapply(X = names(ellenbergDescription), FUN = function(curEllenberg, retPlotInfo, ellenbergValues) {
    outFrame <- cbind(retPlotInfo, data.frame(
      ellenbergType = rep(curEllenberg, nrow(retPlotInfo)),
      ellenbergValue = ellenbergValues[, curEllenberg]
    ))
    rownames(outFrame) <- paste(rownames(retPlotInfo), curEllenberg, sep = "_")
    outFrame
  }, retPlotInfo = retPlotInfo[rowsToUse, ],
    ellenbergValues = ellenbergValues[rowsToUse, ]))
  # Ensure that the Ellenberg type variable and year are stored as factors
  reorderedEllenberg$ellenbergType <- factor(reorderedEllenberg$ellenbergType, levels = names(ellenbergDescription), labels = ellenbergDescription)
  reorderedEllenberg$year <- factor(reorderedEllenberg$year, levels = sort(unique(reorderedEllenberg$year)))
  # Create a data frame of the model outputs
  modelOutputs <- do.call(rbind, lapply(X = names(ellenbergDescription), FUN = function(curEllenberg, retPlotInfo, modelList, ellenbergDescription, rowsToUse) {
    # Retrieve the model outputs
    modelOutputs <- as.matrix(modelList[[curEllenberg]]$summary.fitted.values[rowsToUse, c("mean", "0.025quant", "0.5quant", "0.975quant")])
    # Rescale them to the appropriate Ellenberg scale
    modelOutputs <- attr(ellenbergDescription, "range")["min", curEllenberg] + diff(attr(ellenbergDescription, "range")[, curEllenberg]) * modelOutputs
    colnames(modelOutputs) <- c("ellModMean", "ellModLowerCred", "ellModMedian", "ellModUpperCred")
    modelOutputs
  }, retPlotInfo = retPlotInfo, modelList = modelList, ellenbergDescription = ellenbergDescription, rowsToUse = rowsToUse))
  # Attach the model outputs to the Ellenberg reorder frame
  reorderedEllenberg <- cbind(reorderedEllenberg, modelOutputs)
  lowCred <- function(yin) {quantile(yin, probs = 0.025, names = FALSE)}
  uppCred <- function(yin) {quantile(yin, probs = 0.975, names = FALSE)}
  # Create a violin plot of the Ellenberg values
  violinPlot <- ggplot(reorderedEllenberg, aes(year, ellenbergValue, fill = ellenbergType)) +
    geom_violin() + stat_summary(aes(y = ellModMean), fun.ymax = uppCred, fun.ymin = lowCred, geom = "ribbon", alpha = 0.2, fill = "grey", group = 1) +
    stat_summary(aes(y = ellModMean), fun.y = mean, geom = "line", linetype = "longdash", group = 1) + stat_summary(fun.y = mean, geom = "point", size = 4, colour = "black") +
    facet_grid(ellenbergType ~ ., scales = "free_y") + theme_classic() + theme(legend.position = "none") +
    xlab("√Ör") + ylab("Ellenberg Indikator Verdi") + scale_fill_manual(values = attr(ellenbergDescription, "dispColours"))
  # Create a marginal year effect data frame
  yearEffectFrame <- do.call(rbind, lapply(X = names(ellenbergDescription), FUN = function(curEllenberg, modelList, curSiteCode, ellenbergDescription) {
    # Retrieve the marginal density estimate for the derived yearly effect parameter
    marginalFrame <- modelList[[curEllenberg]]$marginals.lincomb.derived[[curSiteCode]]
    # Retrieve the rescaled credible interval
    credInt <- as.double(diff(attr(ellenbergDescription, "range")[, curEllenberg]) * modelList[[curEllenberg]]$summary.lincomb.derived[curSiteCode, c("0.025quant", "0.975quant")])
    # Create a data frame output of the marginal densities
    outFrame <- data.frame(
      # Rescale the Ellenberg values
      ellenbergValue = marginalFrame[, "x"] * diff(attr(ellenbergDescription, "range")[, curEllenberg]),
      # Add the other Ellenberg information
      density = marginalFrame[, "y"],
      ellenbergType = factor(rep(curEllenberg, nrow(marginalFrame)), levels = names(ellenbergDescription), labels = ellenbergDescription)
    )
    # Add a column to help for the display of the Ellenberg credible interval
    outFrame <- cbind(outFrame, data.frame(
      ellenbergCredInt = ifelse(outFrame$ellenbergValue >= credInt[1] & outFrame$ellenbergValue <= credInt[2], outFrame$ellenbergValue, NA)
    ))
    outFrame
  }, modelList = modelList, curSiteCode = curSiteCode, ellenbergDescription = ellenbergDescription))
  # Create a plot to generate the credible interval
  intervalPlot <- ggplot(yearEffectFrame, aes(ellenbergValue, density)) +
    geom_ribbon(aes(x = ellenbergCredInt, ymax = density, fill = ellenbergType), ymin = 0) + geom_line(group = 1) +
    geom_vline(xintercept = 0.0, linetype = "longdash") +
    facet_grid(ellenbergType ~ ., scales = "free_y") + theme_classic() + theme(legend.position = "none") +
    xlab("Skalert √Örlig Regresjonskoeffisient") + ylab("Tetthet") + scale_fill_manual(values = attr(ellenbergDescription, "dispColours")) +
    scale_x_continuous(limits = range(yearEffectFrame$ellenbergCredInt, na.rm = TRUE) + 0.1 * c(-1.0, 1.0) * diff(range(yearEffectFrame$ellenbergCredInt, na.rm = TRUE)))
  # Combine the plots into one aligned plot
  combinedPlot <- ggdraw() +
    draw_plot(violinPlot, x = 0.0, y = 0.0, height = 1.0, width = 0.6) +
    draw_plot(intervalPlot, x = 0.6, y = 0.0, height = 1.0, width = 0.4)
  # Save the outputs as SVG files
  ggsave(paste(outputLocation, "/", curSiteName, fileSuffix, "Ellenberg.svg", sep = ""), violinPlot, width = 10, height = 12)
  ggsave(paste(outputLocation, "/", curSiteName, fileSuffix, "Ellenberg√ÖrligEndring.svg", sep = ""), intervalPlot, width = 5, height = 12)
  ggsave(paste(outputLocation, "/", curSiteName, fileSuffix, "EllenbergAlle.svg", sep = ""), combinedPlot, width = 15, height = 12)
  # Create a list of output plots
  list(
    violinPlot = violinPlot,
    annualChangePlot = intervalPlot,
    combinedPlot = combinedPlot)
}
# Plot the Ellenberg values for both the frequency and cover values
freqEllenbergPlotList <- apply(X = as.matrix(TOVData$siteInfo), FUN = makeEllenbergPlotList, MARGIN = 1, ellenbergValues = freqEllenbergValues, ellenbergDescription = ellenbergDescriptionNorsk, outputLocation = outputLocation, fileSuffix = "_Frekvens", modelList = freqEllenbergModels)
coverEllenbergPlotList <- apply(X = as.matrix(TOVData$siteInfo), FUN = makeEllenbergPlotList, MARGIN = 1, ellenbergValues = coverEllenbergValues, ellenbergDescription = ellenbergDescriptionNorsk, outputLocation = outputLocation, fileSuffix = "_Dekning", modelList = coverEllenbergModels)
```
